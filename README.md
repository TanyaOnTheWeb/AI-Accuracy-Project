# AI-Accuracy-Project

This project analyzes the performance of an AI model by comparing predicted values with actual results to measure accuracy, detect errors, and identify performance drift over time.

The goal is to understand where AI models succeed, where they fail, and how business teams can improve predictions.

---

## Project Objectives

- Measure AI prediction accuracy
- Track error trends over time (model drift)
- Compare performance across regions and products
- Identify high-error areas

---

## Tools Used

- SQL – data storage and analysis  
- Power BI – interactive dashboard and visualizations  
- Excel/CSV – dataset preparation  

---

## Project Structure

AI-Accuracy-Project  
│  
├── Dataset  
│   └── ai_predictions.csv  
├── SQL  
│   └── analysis.sql  
├── PowerBI  
│   └── dashboard.pbix  
└── Insights  
    └── insights_report.pdf  

---

## Key Metrics

- Overall Accuracy Percentage  
- Average Prediction Error  
- Error Trend (Drift Detection)  
- Region-wise Performance  
- Predicted vs Actual Comparison  

---

## Key Insights

- AI accuracy varies across regions  
- Certain products show higher prediction errors  
- Performance drift observed over time  
- Regular retraining is recommended  

---

## Business Value

This project demonstrates how analytics can:

- Monitor AI system reliability  
- Reduce forecasting errors  
- Improve operational decision-making  
- Detect early performance issues  

---

## Future Improvements

- Add larger real-world datasets  
- Automate performance alerts  
- Integrate real AI model predictions  
- Add forecasting evaluation metrics  

---

## Created By

Tanya Singh Rajput
Data Analyst | SQL | Power BI | Analytics  

